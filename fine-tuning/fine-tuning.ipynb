{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2TokenizerFast\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(protocol):\n",
    "    chunks = []\n",
    "    page = 0\n",
    "    chunk_tokens = 0\n",
    "\n",
    "    while page < len(protocol):\n",
    "        page_count = 0\n",
    "        chunk_tokens = 0\n",
    "        chunk = ''\n",
    "        while chunk_tokens <= 3500 and page_count < 5 and page < len(protocol):\n",
    "            chunk += protocol.iloc[page][2]\n",
    "            chunk_tokens += len(tokenizer(chunk)[0])\n",
    "            page += 1\n",
    "            page_count += 1\n",
    "        chunks.append(chunk)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_writer(chunks, protocol):\n",
    "    if not os.path.exists(f\"jsons/{protocol}\"):\n",
    "            os.makedirs(f\"jsons/{protocol}\")\n",
    "    \n",
    "    for count, chunk in enumerate(chunks):\n",
    "        chunk_dict = {\n",
    "            \"prompt\": chunk,\n",
    "            \"completion\" : \"\"\n",
    "        }\n",
    "        with open(f\"jsons/{protocol}/{protocol}-{count}.json\", \"w\") as f:\n",
    "            json.dump(chunk_dict, f)\n",
    "    print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for protocol in os.listdir(r'C:\\Users\\Jakub\\Documents\\zazu\\openai-quickstart-python\\textract'):\n",
    "    path = f\"{protocol}/text.csv\"\n",
    "    name = protocol\n",
    "    try:\n",
    "        data = pd.read_csv(path)\n",
    "        text = data.astype(str)\n",
    "        chunks = chunker(text)\n",
    "        \n",
    "        \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\Jakub\\Documents\\zazu\\openai-quickstart-python\\textract\\trial0002\\text.csv\")\n",
    "trial = \"trial0002\"\n",
    "text = data.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['Non-Interventional Study Protocol', 'Study Short Title', 'Evaluation of the sensitivity and specificity of a novel quality of life (QoL)', 'tool to assess the treatment satisfaction in psoriasis patients', 'STUDY IDENTIFICATION No. 2020-A00652-37', 'Full Study Title', 'Evaluation of the sensitivity and specificity, compared to DLQI as a standard tool, of a novel', 'QoL questionnaire (treat to the PSOriasis patient satiSfactiOn TARGET) among moderate to', 'severe psoriasis patients treated with brodalumab (Kyntheum)', 'GPP statement:', 'This Non-Interventional Study will be conducted in compliance with the', 'Clinical Study Protocol, Good Pharmacoepidemiology Practices and', 'applicable regulatory requirement(s)', 'Sponsoring entity:', 'LEO Study ID: PSO-TARGET', 'LEO Pharma France', '2 rue RenÃ© Caudron', 'Date: 25-05-2020', '215 avenue Georges Clemenceau', '78960 Voisins-Le-Bretonneux', 'Version: 2.0']\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[\"Text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2TokenizerFast\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1507 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"jsons/trial0002\"):\n",
    "        os.makedirs(\"jsons/trial0002\")\n",
    "\n",
    "for count, chunk in enumerate(chunks):\n",
    "    chunk_dict = {\n",
    "        \"prompt\": chunk,\n",
    "        \"completion\" : \"\"\n",
    "    }\n",
    "    with open(f\"jsons/trial0002/trial0002-{count}.json\", \"w\") as f:\n",
    "        json.dump(chunk_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"prompt\" : \"\"\" \"\"\" ,\n",
    "    \"completion\" : \"\"\" \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12d4f619691cb3c8cdb4fc1bac3542d3bd06428ac0d8596b7ce847b27c5c0d5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
